<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.4" />
<title>cytograph.clustering.polished_leiden API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>cytograph.clustering.polished_leiden</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import logging

import leidenalg as la
import igraph
import numpy as np
from cytograph import requires, creates, Module
import shoji
from sklearn.neighbors import NearestNeighbors
from sklearn.cluster import DBSCAN
from sklearn.decomposition import PCA
from sklearn.preprocessing import LabelEncoder


def is_outlier(points: np.ndarray, thresh: float = 3.5) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Returns a boolean array with True if points are outliers and False
        otherwise.

        Parameters:
        -----------
                points : An numobservations by numdimensions array of observations
                thresh : The modified z-score to use as a threshold. Observations with
                        a modified z-score (based on the median absolute deviation) greater
                        than this value will be classified as outliers.

        Returns:
        --------
                mask : A numobservations-length boolean array.

        References:
        ----------
                Boris Iglewicz and David Hoaglin (1993), &#34;Volume 16: How to Detect and
                Handle Outliers&#34;, The ASQC Basic References in Quality Control:
                Statistical Techniques, Edward F. Mykytka, Ph.D., Editor.
        &#34;&#34;&#34;
        if len(points.shape) == 1:
                points = points[:, None]
        median = np.median(points, axis=0)
        diff = np.sum((points - median)**2, axis=-1)
        diff = np.sqrt(diff)
        med_abs_deviation = np.median(diff)

        modified_z_score = 0.6745 * diff / med_abs_deviation

        return modified_z_score &gt; thresh


class PolishedLeiden(Module):
        def __init__(self, resolution: float = 1.0, method: str = &#34;modularity&#34;, max_size: int = 0, min_size: int = 25, **kwargs) -&gt; None:
                super().__init__(**kwargs)
                self.resolution = resolution
                ptypes = {
                        &#34;modularity&#34;: la.ModularityVertexPartition,
                        &#34;cpm&#34;: la.CPMVertexPartition,
                        &#34;surprise&#34;: la.SurpriseVertexPartition,
                        &#34;rb&#34;: la.RBConfigurationVertexPartition,
                        &#34;rber&#34;: la.RBERVertexPartition,
                        &#34;significance&#34;: la.SignificanceVertexPartition
                }
                if method.lower() in ptypes:
                        self.method = ptypes[method.lower()]
                else:
                        raise ValueError(f&#34;Invalid partition method &#39;{method}&#39;&#34;)
                self.max_size = max_size
                self.min_size = min_size

        def _break_cluster(self, embedding: np.ndarray) -&gt; np.ndarray:
                &#34;&#34;&#34;
                If needed, split the cluster by density clustering on the embedding

                Returns:
                        An array of cluster labels (all zeros if cluster wasn&#39;t split)
                        Note: the returned array may contain -1 for outliers
                &#34;&#34;&#34;
                # Find outliers in either dimension using Grubbs test
                xy = PCA().fit_transform(embedding)
                x = xy[:, 0]
                y = xy[:, 1]
                # Standardize x and y (not sure if this is really necessary)
                x = (x - x.mean()) / x.std()
                y = (y - y.mean()) / y.std()
                xy = np.vstack([x, y]).transpose()

                outliers = np.zeros(embedding.shape[0], dtype=&#39;bool&#39;)
                for _ in range(5):
                        outliers[~outliers] = is_outlier(x[~outliers])
                        outliers[~outliers] = is_outlier(y[~outliers])

                # See if the cluster is very dispersed
                min_pts = min(50, min(x.shape[0] - 1, max(5, round(0.1 * x.shape[0]))))
                nn = NearestNeighbors(n_neighbors=min_pts, algorithm=&#34;ball_tree&#34;, n_jobs=4)
                nn.fit(xy)
                knn = nn.kneighbors_graph(mode=&#39;distance&#39;)
                k_radius = knn.max(axis=1).toarray()
                epsilon = np.percentile(k_radius, 70)
                # Not too many outliers, and not too dispersed
                if outliers.sum() &lt;= 3 and (np.sqrt(x**2 + y**2) &lt; epsilon).sum() &gt;= min_pts * 0.5:
                        return np.zeros(embedding.shape[0], dtype=&#39;int&#39;)

                # Too many outliers, or too dispersed
                clusterer = DBSCAN(eps=epsilon, min_samples=round(min_pts * 0.5))
                labels = clusterer.fit_predict(xy)

                # Assign each outlier to the same cluster as the nearest non-outlier
                nn = NearestNeighbors(n_neighbors=50, algorithm=&#34;ball_tree&#34;)
                nn.fit(xy[labels &gt;= 0])
                nearest = nn.kneighbors(xy[labels == -1], n_neighbors=1, return_distance=False)
                labels[labels == -1] = labels[labels &gt;= 0][nearest.flat[:]]
                return labels


        @requires(&#34;Embedding&#34;, &#34;float32&#34;, (&#34;cells&#34;, 2))
        @requires(&#34;ManifoldIndices&#34;, &#34;uint32&#34;, (None, 2))
        @requires(&#34;ManifoldWeights&#34;, &#34;float32&#34;, (None))
        @creates(&#34;Clusters&#34;, &#34;uint32&#34;, (&#34;cells&#34;,))
        def fit(self, ws: shoji.WorkspaceManager, save: bool = False) -&gt; np.ndarray:
                &#34;&#34;&#34;
                Given a sparse adjacency matrix, perform Leiden clustering

                Args:
                        ws              The shoji Workspace

                Returns:
                        labels: The cluster labels
                &#34;&#34;&#34;
                logging.info(&#34; PolishedLeiden: Loading the graph&#34;)
                rc = self.ManifoldIndices[...]
                g = igraph.Graph(ws.cells.length, list(zip(rc[:, 0].T.tolist(), rc[:, 1].T.tolist())), directed=False, edge_attrs={&#39;weight&#39;: self.ManifoldWeights[...]})
                logging.info(&#34; PolishedLeiden: Optimizing the graph partitioning&#34;)
                if self.resolution != 1:
                        labels = np.array(la.find_partition(g, self.method, weights=self.ManifoldWeights[...], max_comm_size=self.max_size, resolution_parameter=self.resolution, n_iterations=-1).membership)
                else:
                        labels = np.array(la.find_partition(g, self.method, weights=self.ManifoldWeights[...], max_comm_size=self.max_size, n_iterations=-1).membership)
                logging.info(f&#34; PolishedLeiden: Found {labels.max() + 1} initial clusters&#34;)

                # Break clusters based on the embedding
                logging.info(&#34; PolishedLeiden: Breaking clusters based on the embedding&#34;)
                xy = self.Embedding[...]
                # Only break clusters that are at least twice as large as the minimum size (note: labels are sorted by cluster size)
                max_label = np.where(np.bincount(labels) &lt; self.min_size * 2)[0][0]
                next_label = 0
                labels2 = np.copy(labels)
                for lbl in range(max_label):
                        cluster = labels == lbl
                        if cluster.sum() &lt; 10:
                                continue
                        adjusted = self._break_cluster(xy[cluster, :])
                        new_labels = np.copy(adjusted)
                        for i in range(np.max(adjusted) + 1):
                                new_labels[adjusted == i] = i + next_label
                        next_label = next_label + np.max(adjusted) + 1
                        labels2[cluster] = new_labels
                labels = labels2
                logging.info(f&#34; PolishedLeiden: Found {labels.max() + 1} clusters after breaking clusters on the embedding&#34;)

                # Assign each orphan cell to the same cluster as the nearest non-orphan
                logging.info(f&#34; PolishedLeiden: Reassigning cells from clusters with less than {self.min_size} cells&#34;)
                too_small = np.isin(labels, np.where(np.bincount(labels) &lt; self.min_size)[0])

                nn = NearestNeighbors(n_neighbors=50, algorithm=&#34;ball_tree&#34;)
                nn.fit(xy[~too_small])
                nearest = nn.kneighbors(xy[too_small], n_neighbors=1, return_distance=False)
                labels[too_small] = labels[~too_small][nearest.flat[:]]

                logging.info(f&#34; PolishedLeiden: Found {labels.max() + 1} clusters&#34;)
                return labels</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="cytograph.clustering.polished_leiden.is_outlier"><code class="name flex">
<span>def <span class="ident">is_outlier</span></span>(<span>points: numpy.ndarray, thresh: float = 3.5) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a boolean array with True if points are outliers and False
otherwise.</p>
<h2 id="parameters">Parameters:</h2>
<pre><code>    points : An numobservations by numdimensions array of observations
    thresh : The modified z-score to use as a threshold. Observations with
            a modified z-score (based on the median absolute deviation) greater
            than this value will be classified as outliers.
</code></pre>
<h2 id="returns">Returns:</h2>
<pre><code>    mask : A numobservations-length boolean array.
</code></pre>
<h2 id="references">References:</h2>
<pre><code>    Boris Iglewicz and David Hoaglin (1993), "Volume 16: How to Detect and
    Handle Outliers", The ASQC Basic References in Quality Control:
    Statistical Techniques, Edward F. Mykytka, Ph.D., Editor.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_outlier(points: np.ndarray, thresh: float = 3.5) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Returns a boolean array with True if points are outliers and False
        otherwise.

        Parameters:
        -----------
                points : An numobservations by numdimensions array of observations
                thresh : The modified z-score to use as a threshold. Observations with
                        a modified z-score (based on the median absolute deviation) greater
                        than this value will be classified as outliers.

        Returns:
        --------
                mask : A numobservations-length boolean array.

        References:
        ----------
                Boris Iglewicz and David Hoaglin (1993), &#34;Volume 16: How to Detect and
                Handle Outliers&#34;, The ASQC Basic References in Quality Control:
                Statistical Techniques, Edward F. Mykytka, Ph.D., Editor.
        &#34;&#34;&#34;
        if len(points.shape) == 1:
                points = points[:, None]
        median = np.median(points, axis=0)
        diff = np.sum((points - median)**2, axis=-1)
        diff = np.sqrt(diff)
        med_abs_deviation = np.median(diff)

        modified_z_score = 0.6745 * diff / med_abs_deviation

        return modified_z_score &gt; thresh</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="cytograph.clustering.polished_leiden.PolishedLeiden"><code class="flex name class">
<span>class <span class="ident">PolishedLeiden</span></span>
<span>(</span><span>resolution: float = 1.0, method: str = 'modularity', max_size: int = 0, min_size: int = 25, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PolishedLeiden(Module):
        def __init__(self, resolution: float = 1.0, method: str = &#34;modularity&#34;, max_size: int = 0, min_size: int = 25, **kwargs) -&gt; None:
                super().__init__(**kwargs)
                self.resolution = resolution
                ptypes = {
                        &#34;modularity&#34;: la.ModularityVertexPartition,
                        &#34;cpm&#34;: la.CPMVertexPartition,
                        &#34;surprise&#34;: la.SurpriseVertexPartition,
                        &#34;rb&#34;: la.RBConfigurationVertexPartition,
                        &#34;rber&#34;: la.RBERVertexPartition,
                        &#34;significance&#34;: la.SignificanceVertexPartition
                }
                if method.lower() in ptypes:
                        self.method = ptypes[method.lower()]
                else:
                        raise ValueError(f&#34;Invalid partition method &#39;{method}&#39;&#34;)
                self.max_size = max_size
                self.min_size = min_size

        def _break_cluster(self, embedding: np.ndarray) -&gt; np.ndarray:
                &#34;&#34;&#34;
                If needed, split the cluster by density clustering on the embedding

                Returns:
                        An array of cluster labels (all zeros if cluster wasn&#39;t split)
                        Note: the returned array may contain -1 for outliers
                &#34;&#34;&#34;
                # Find outliers in either dimension using Grubbs test
                xy = PCA().fit_transform(embedding)
                x = xy[:, 0]
                y = xy[:, 1]
                # Standardize x and y (not sure if this is really necessary)
                x = (x - x.mean()) / x.std()
                y = (y - y.mean()) / y.std()
                xy = np.vstack([x, y]).transpose()

                outliers = np.zeros(embedding.shape[0], dtype=&#39;bool&#39;)
                for _ in range(5):
                        outliers[~outliers] = is_outlier(x[~outliers])
                        outliers[~outliers] = is_outlier(y[~outliers])

                # See if the cluster is very dispersed
                min_pts = min(50, min(x.shape[0] - 1, max(5, round(0.1 * x.shape[0]))))
                nn = NearestNeighbors(n_neighbors=min_pts, algorithm=&#34;ball_tree&#34;, n_jobs=4)
                nn.fit(xy)
                knn = nn.kneighbors_graph(mode=&#39;distance&#39;)
                k_radius = knn.max(axis=1).toarray()
                epsilon = np.percentile(k_radius, 70)
                # Not too many outliers, and not too dispersed
                if outliers.sum() &lt;= 3 and (np.sqrt(x**2 + y**2) &lt; epsilon).sum() &gt;= min_pts * 0.5:
                        return np.zeros(embedding.shape[0], dtype=&#39;int&#39;)

                # Too many outliers, or too dispersed
                clusterer = DBSCAN(eps=epsilon, min_samples=round(min_pts * 0.5))
                labels = clusterer.fit_predict(xy)

                # Assign each outlier to the same cluster as the nearest non-outlier
                nn = NearestNeighbors(n_neighbors=50, algorithm=&#34;ball_tree&#34;)
                nn.fit(xy[labels &gt;= 0])
                nearest = nn.kneighbors(xy[labels == -1], n_neighbors=1, return_distance=False)
                labels[labels == -1] = labels[labels &gt;= 0][nearest.flat[:]]
                return labels


        @requires(&#34;Embedding&#34;, &#34;float32&#34;, (&#34;cells&#34;, 2))
        @requires(&#34;ManifoldIndices&#34;, &#34;uint32&#34;, (None, 2))
        @requires(&#34;ManifoldWeights&#34;, &#34;float32&#34;, (None))
        @creates(&#34;Clusters&#34;, &#34;uint32&#34;, (&#34;cells&#34;,))
        def fit(self, ws: shoji.WorkspaceManager, save: bool = False) -&gt; np.ndarray:
                &#34;&#34;&#34;
                Given a sparse adjacency matrix, perform Leiden clustering

                Args:
                        ws              The shoji Workspace

                Returns:
                        labels: The cluster labels
                &#34;&#34;&#34;
                logging.info(&#34; PolishedLeiden: Loading the graph&#34;)
                rc = self.ManifoldIndices[...]
                g = igraph.Graph(ws.cells.length, list(zip(rc[:, 0].T.tolist(), rc[:, 1].T.tolist())), directed=False, edge_attrs={&#39;weight&#39;: self.ManifoldWeights[...]})
                logging.info(&#34; PolishedLeiden: Optimizing the graph partitioning&#34;)
                if self.resolution != 1:
                        labels = np.array(la.find_partition(g, self.method, weights=self.ManifoldWeights[...], max_comm_size=self.max_size, resolution_parameter=self.resolution, n_iterations=-1).membership)
                else:
                        labels = np.array(la.find_partition(g, self.method, weights=self.ManifoldWeights[...], max_comm_size=self.max_size, n_iterations=-1).membership)
                logging.info(f&#34; PolishedLeiden: Found {labels.max() + 1} initial clusters&#34;)

                # Break clusters based on the embedding
                logging.info(&#34; PolishedLeiden: Breaking clusters based on the embedding&#34;)
                xy = self.Embedding[...]
                # Only break clusters that are at least twice as large as the minimum size (note: labels are sorted by cluster size)
                max_label = np.where(np.bincount(labels) &lt; self.min_size * 2)[0][0]
                next_label = 0
                labels2 = np.copy(labels)
                for lbl in range(max_label):
                        cluster = labels == lbl
                        if cluster.sum() &lt; 10:
                                continue
                        adjusted = self._break_cluster(xy[cluster, :])
                        new_labels = np.copy(adjusted)
                        for i in range(np.max(adjusted) + 1):
                                new_labels[adjusted == i] = i + next_label
                        next_label = next_label + np.max(adjusted) + 1
                        labels2[cluster] = new_labels
                labels = labels2
                logging.info(f&#34; PolishedLeiden: Found {labels.max() + 1} clusters after breaking clusters on the embedding&#34;)

                # Assign each orphan cell to the same cluster as the nearest non-orphan
                logging.info(f&#34; PolishedLeiden: Reassigning cells from clusters with less than {self.min_size} cells&#34;)
                too_small = np.isin(labels, np.where(np.bincount(labels) &lt; self.min_size)[0])

                nn = NearestNeighbors(n_neighbors=50, algorithm=&#34;ball_tree&#34;)
                nn.fit(xy[~too_small])
                nearest = nn.kneighbors(xy[too_small], n_neighbors=1, return_distance=False)
                labels[too_small] = labels[~too_small][nearest.flat[:]]

                logging.info(f&#34; PolishedLeiden: Found {labels.max() + 1} clusters&#34;)
                return labels</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="cytograph.module.Module" href="../module.html#cytograph.module.Module">Module</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="cytograph.clustering.polished_leiden.PolishedLeiden.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, ws: shoji.workspace.WorkspaceManager, save: bool = False) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Given a sparse adjacency matrix, perform Leiden clustering</p>
<h2 id="args">Args</h2>
<p>ws
The shoji Workspace</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>labels</code></dt>
<dd>The cluster labels</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@requires(&#34;Embedding&#34;, &#34;float32&#34;, (&#34;cells&#34;, 2))
@requires(&#34;ManifoldIndices&#34;, &#34;uint32&#34;, (None, 2))
@requires(&#34;ManifoldWeights&#34;, &#34;float32&#34;, (None))
@creates(&#34;Clusters&#34;, &#34;uint32&#34;, (&#34;cells&#34;,))
def fit(self, ws: shoji.WorkspaceManager, save: bool = False) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Given a sparse adjacency matrix, perform Leiden clustering

        Args:
                ws              The shoji Workspace

        Returns:
                labels: The cluster labels
        &#34;&#34;&#34;
        logging.info(&#34; PolishedLeiden: Loading the graph&#34;)
        rc = self.ManifoldIndices[...]
        g = igraph.Graph(ws.cells.length, list(zip(rc[:, 0].T.tolist(), rc[:, 1].T.tolist())), directed=False, edge_attrs={&#39;weight&#39;: self.ManifoldWeights[...]})
        logging.info(&#34; PolishedLeiden: Optimizing the graph partitioning&#34;)
        if self.resolution != 1:
                labels = np.array(la.find_partition(g, self.method, weights=self.ManifoldWeights[...], max_comm_size=self.max_size, resolution_parameter=self.resolution, n_iterations=-1).membership)
        else:
                labels = np.array(la.find_partition(g, self.method, weights=self.ManifoldWeights[...], max_comm_size=self.max_size, n_iterations=-1).membership)
        logging.info(f&#34; PolishedLeiden: Found {labels.max() + 1} initial clusters&#34;)

        # Break clusters based on the embedding
        logging.info(&#34; PolishedLeiden: Breaking clusters based on the embedding&#34;)
        xy = self.Embedding[...]
        # Only break clusters that are at least twice as large as the minimum size (note: labels are sorted by cluster size)
        max_label = np.where(np.bincount(labels) &lt; self.min_size * 2)[0][0]
        next_label = 0
        labels2 = np.copy(labels)
        for lbl in range(max_label):
                cluster = labels == lbl
                if cluster.sum() &lt; 10:
                        continue
                adjusted = self._break_cluster(xy[cluster, :])
                new_labels = np.copy(adjusted)
                for i in range(np.max(adjusted) + 1):
                        new_labels[adjusted == i] = i + next_label
                next_label = next_label + np.max(adjusted) + 1
                labels2[cluster] = new_labels
        labels = labels2
        logging.info(f&#34; PolishedLeiden: Found {labels.max() + 1} clusters after breaking clusters on the embedding&#34;)

        # Assign each orphan cell to the same cluster as the nearest non-orphan
        logging.info(f&#34; PolishedLeiden: Reassigning cells from clusters with less than {self.min_size} cells&#34;)
        too_small = np.isin(labels, np.where(np.bincount(labels) &lt; self.min_size)[0])

        nn = NearestNeighbors(n_neighbors=50, algorithm=&#34;ball_tree&#34;)
        nn.fit(xy[~too_small])
        nearest = nn.kneighbors(xy[too_small], n_neighbors=1, return_distance=False)
        labels[too_small] = labels[~too_small][nearest.flat[:]]

        logging.info(f&#34; PolishedLeiden: Found {labels.max() + 1} clusters&#34;)
        return labels</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="cytograph.clustering" href="index.html">cytograph.clustering</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="cytograph.clustering.polished_leiden.is_outlier" href="#cytograph.clustering.polished_leiden.is_outlier">is_outlier</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="cytograph.clustering.polished_leiden.PolishedLeiden" href="#cytograph.clustering.polished_leiden.PolishedLeiden">PolishedLeiden</a></code></h4>
<ul class="">
<li><code><a title="cytograph.clustering.polished_leiden.PolishedLeiden.fit" href="#cytograph.clustering.polished_leiden.PolishedLeiden.fit">fit</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.4</a>.</p>
</footer>
</body>
</html>