<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.4" />
<title>cytograph.clustering.polished_louvain API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>cytograph.clustering.polished_louvain</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import logging

import community
import networkx as nx
import numpy as np
from scipy.stats import mode
from sklearn.cluster import DBSCAN
from sklearn.decomposition import PCA
from sklearn.neighbors import NearestNeighbors
import scipy.sparse as sparse
from cytograph import requires, creates, Module
import shoji


def is_outlier(points: np.ndarray, thresh: float = 3.5) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Returns a boolean array with True if points are outliers and False
        otherwise.

        Parameters:
        -----------
                points : An numobservations by numdimensions array of observations
                thresh : The modified z-score to use as a threshold. Observations with
                        a modified z-score (based on the median absolute deviation) greater
                        than this value will be classified as outliers.

        Returns:
        --------
                mask : A numobservations-length boolean array.

        References:
        ----------
                Boris Iglewicz and David Hoaglin (1993), &#34;Volume 16: How to Detect and
                Handle Outliers&#34;, The ASQC Basic References in Quality Control:
                Statistical Techniques, Edward F. Mykytka, Ph.D., Editor.
        &#34;&#34;&#34;
        if len(points.shape) == 1:
                points = points[:, None]
        median = np.median(points, axis=0)
        diff = np.sum((points - median)**2, axis=-1)
        diff = np.sqrt(diff)
        med_abs_deviation = np.median(diff)

        modified_z_score = 0.6745 * diff / med_abs_deviation

        return modified_z_score &gt; thresh


class PolishedLouvain(Module):
        def __init__(self, resolution: float = 1.0, min_cells: int = 10, **kwargs) -&gt; None:
                super().__init__(**kwargs)
                self.resolution = resolution
                self.min_cells = min_cells

        def _break_cluster(self, embedding: np.ndarray) -&gt; np.ndarray:
                &#34;&#34;&#34;
                If needed, split the cluster by density clustering on the embedding

                Returns:
                        An array of cluster labels (all zeros if cluster wasn&#39;t split)
                        Note: the returned array may contain -1 for outliers
                &#34;&#34;&#34;
                # Find outliers in either dimension using Grubbs test
                xy = PCA().fit_transform(embedding)
                x = xy[:, 0]
                y = xy[:, 1]
                # Standardize x and y (not sure if this is really necessary)
                x = (x - x.mean()) / x.std()
                y = (y - y.mean()) / y.std()
                xy = np.vstack([x, y]).transpose()

                outliers = np.zeros(embedding.shape[0], dtype=&#39;bool&#39;)
                for _ in range(5):
                        outliers[~outliers] = is_outlier(x[~outliers])
                        outliers[~outliers] = is_outlier(y[~outliers])

                # See if the cluster is very dispersed
                min_pts = min(50, min(x.shape[0] - 1, max(5, round(0.1 * x.shape[0]))))
                nn = NearestNeighbors(n_neighbors=min_pts, algorithm=&#34;ball_tree&#34;, n_jobs=4)
                nn.fit(xy)
                knn = nn.kneighbors_graph(mode=&#39;distance&#39;)
                k_radius = knn.max(axis=1).toarray()
                epsilon = np.percentile(k_radius, 70)
                # Not too many outliers, and not too dispersed
                if outliers.sum() &lt;= 3 and (np.sqrt(x**2 + y**2) &lt; epsilon).sum() &gt;= min_pts * 0.5:
                        return np.zeros(embedding.shape[0], dtype=&#39;int&#39;)

                # Too many outliers, or too dispersed
                clusterer = DBSCAN(eps=epsilon, min_samples=round(min_pts * 0.5))
                return clusterer.fit_predict(xy)

        @requires(&#34;Embedding&#34;, &#34;float32&#34;, (&#34;cells&#34;, 2))
        @requires(&#34;ManifoldIndices&#34;, &#34;uint32&#34;, (None, 2))
        @requires(&#34;ManifoldWeights&#34;, &#34;float32&#34;, (None))
        @creates(&#34;Clusters&#34;, &#34;uint32&#34;, (&#34;cells&#34;,))
        def fit(self, ws: shoji.WorkspaceManager, save: bool = False) -&gt; np.ndarray:
                &#34;&#34;&#34;
                Given a sparse adjacency matrix, perform Louvain clustering, then polish the result

                Args:
                        ws              The shoji Workspace

                Returns:
                        labels: The cluster labels
                &#34;&#34;&#34;
                logging.info(&#34; PolishedLouvain: Louvain community detection&#34;)
                rc = self.ManifoldIndices[...]
                knn = sparse.coo_matrix((self.ManifoldWeights[...], (rc[:, 0].T, rc[:, 1].T)))
                g = nx.from_scipy_sparse_matrix(knn)
                partitions = community.best_partition(g, resolution=self.resolution, randomize=False)
                labels = np.array([partitions[key] for key in range(knn.shape[0])])
                logging.info(f&#34; PolishedLouvain: Found {labels.max() + 1} initial clusters&#34;)

                # Mark outliers using DBSCAN on the embedding
                logging.info(&#34; PolishedLouvain: Using DBSCAN to mark outliers&#34;)
                xy = self.Embedding[...]
                nn = NearestNeighbors(n_neighbors=10, algorithm=&#34;ball_tree&#34;, n_jobs=-1)
                nn.fit(xy)
                knn = nn.kneighbors_graph(mode=&#39;distance&#39;)
                k_radius = knn.max(axis=1).toarray()
                epsilon = np.percentile(k_radius, 80)
                clusterer = DBSCAN(eps=epsilon, min_samples=10)
                outliers = (clusterer.fit_predict(xy) == -1)
                labels[outliers] = -1
                logging.info(f&#34; PolishedLouvain: Found {labels.max() + 1} clusters after marking outliers using DBSCAN&#34;)

                # Mark outliers as cells in bad neighborhoods
                logging.info(&#34; PolishedLouvain: Using neighborhood to mark outliers&#34;)
                knn = nn.kneighbors_graph(mode=&#39;connectivity&#39;).tocoo()
                temp = []
                for ix in range(labels.shape[0]):
                        if labels[ix] == -1:
                                temp.append(-1)
                                continue
                        neighbors = knn.col[np.where(knn.row == ix)[0]]
                        neighborhood = labels[neighbors] == labels[ix]
                        if neighborhood.sum() / neighborhood.shape[0] &gt; 0.2:
                                temp.append(labels[ix])
                        else:
                                temp.append(-1)
                labels = np.array(temp)

                # Renumber the clusters
                retain = sorted(list(set(labels)))
                d = dict(zip(retain, np.arange(-1, len(set(retain)))))
                labels = np.array([d[x] if x in d else -1 for x in labels])
                logging.info(f&#34; PolishedLouvain: Found {labels.max() + 1} clusters after marking outliers using neighborhood&#34;)

                # Break clusters based on the embedding
                logging.info(&#34; PolishedLouvain: Breaking clusters&#34;)
                max_label = 0
                labels2 = np.copy(labels)
                for lbl in range(labels.max() + 1):
                        cluster = labels == lbl
                        if cluster.sum() &lt; 10:
                                continue
                        adjusted = self._break_cluster(xy[cluster, :])
                        new_labels = np.copy(adjusted)
                        for i in range(np.max(adjusted) + 1):
                                new_labels[adjusted == i] = i + max_label
                        max_label = max_label + np.max(adjusted) + 1
                        labels2[cluster] = new_labels
                labels = labels2
                logging.info(f&#34; PolishedLouvain: Found {labels.max() + 1} clusters after breaking clusters on the embedding&#34;)

                # Set the local cluster label to the local majority vote
                logging.info(&#34; PolishedLouvain: Smoothing cluster identity on the embedding&#34;)
                nn = NearestNeighbors(n_neighbors=10, algorithm=&#34;ball_tree&#34;, n_jobs=4)
                nn.fit(xy)
                knn = nn.kneighbors_graph(mode=&#39;connectivity&#39;).tocoo()
                temp = []
                for ix in range(labels.shape[0]):
                        neighbors = knn.col[np.where(knn.row == ix)[0]]
                        temp.append(mode(labels[neighbors])[0][0])
                labels = np.array(temp)
                logging.info(f&#34; PolishedLouvain: Found {labels.max() + 1} clusters after smoothing clusters on the embedding&#34;)

                # Mark tiny clusters as outliers
                logging.info(&#34; PolishedLouvain: Marking tiny clusters as outliers&#34;)
                ix, counts = np.unique(labels, return_counts=True)
                labels[np.isin(labels, ix[counts &lt; self.min_cells])] = -1

                # Renumber the clusters (since some clusters might have been lost in poor neighborhoods)
                retain = list(set(labels))
                if -1 not in retain:
                        retain.append(-1)
                retain = sorted(retain)
                d = dict(zip(retain, np.arange(-1, len(set(retain)))))
                labels = np.array([d[x] if x in d else -1 for x in labels])
                logging.info(f&#34; PolishedLouvain: Found {labels.max() + 1} clusters after marking tiny clusters as outliers&#34;)

                if np.all(labels &lt; 0):
                        logging.warn(&#34; PolishedLouvain: All cells were determined to be outliers!&#34;)
                        return np.zeros_like(labels)

                if np.any(labels == -1):
                        # Assign each outlier to the same cluster as the nearest non-outlier
                        nn = NearestNeighbors(n_neighbors=50, algorithm=&#34;ball_tree&#34;)
                        nn.fit(xy[labels &gt;= 0])
                        nearest = nn.kneighbors(xy[labels == -1], n_neighbors=1, return_distance=False)
                        labels[labels == -1] = labels[labels &gt;= 0][nearest.flat[:]]
                logging.info(f&#34; PolishedLouvain: Found {labels.max() + 1} clusters&#34;)
                return labels</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="cytograph.clustering.polished_louvain.is_outlier"><code class="name flex">
<span>def <span class="ident">is_outlier</span></span>(<span>points: numpy.ndarray, thresh: float = 3.5) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a boolean array with True if points are outliers and False
otherwise.</p>
<h2 id="parameters">Parameters:</h2>
<pre><code>    points : An numobservations by numdimensions array of observations
    thresh : The modified z-score to use as a threshold. Observations with
            a modified z-score (based on the median absolute deviation) greater
            than this value will be classified as outliers.
</code></pre>
<h2 id="returns">Returns:</h2>
<pre><code>    mask : A numobservations-length boolean array.
</code></pre>
<h2 id="references">References:</h2>
<pre><code>    Boris Iglewicz and David Hoaglin (1993), "Volume 16: How to Detect and
    Handle Outliers", The ASQC Basic References in Quality Control:
    Statistical Techniques, Edward F. Mykytka, Ph.D., Editor.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_outlier(points: np.ndarray, thresh: float = 3.5) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Returns a boolean array with True if points are outliers and False
        otherwise.

        Parameters:
        -----------
                points : An numobservations by numdimensions array of observations
                thresh : The modified z-score to use as a threshold. Observations with
                        a modified z-score (based on the median absolute deviation) greater
                        than this value will be classified as outliers.

        Returns:
        --------
                mask : A numobservations-length boolean array.

        References:
        ----------
                Boris Iglewicz and David Hoaglin (1993), &#34;Volume 16: How to Detect and
                Handle Outliers&#34;, The ASQC Basic References in Quality Control:
                Statistical Techniques, Edward F. Mykytka, Ph.D., Editor.
        &#34;&#34;&#34;
        if len(points.shape) == 1:
                points = points[:, None]
        median = np.median(points, axis=0)
        diff = np.sum((points - median)**2, axis=-1)
        diff = np.sqrt(diff)
        med_abs_deviation = np.median(diff)

        modified_z_score = 0.6745 * diff / med_abs_deviation

        return modified_z_score &gt; thresh</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="cytograph.clustering.polished_louvain.PolishedLouvain"><code class="flex name class">
<span>class <span class="ident">PolishedLouvain</span></span>
<span>(</span><span>resolution: float = 1.0, min_cells: int = 10, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PolishedLouvain(Module):
        def __init__(self, resolution: float = 1.0, min_cells: int = 10, **kwargs) -&gt; None:
                super().__init__(**kwargs)
                self.resolution = resolution
                self.min_cells = min_cells

        def _break_cluster(self, embedding: np.ndarray) -&gt; np.ndarray:
                &#34;&#34;&#34;
                If needed, split the cluster by density clustering on the embedding

                Returns:
                        An array of cluster labels (all zeros if cluster wasn&#39;t split)
                        Note: the returned array may contain -1 for outliers
                &#34;&#34;&#34;
                # Find outliers in either dimension using Grubbs test
                xy = PCA().fit_transform(embedding)
                x = xy[:, 0]
                y = xy[:, 1]
                # Standardize x and y (not sure if this is really necessary)
                x = (x - x.mean()) / x.std()
                y = (y - y.mean()) / y.std()
                xy = np.vstack([x, y]).transpose()

                outliers = np.zeros(embedding.shape[0], dtype=&#39;bool&#39;)
                for _ in range(5):
                        outliers[~outliers] = is_outlier(x[~outliers])
                        outliers[~outliers] = is_outlier(y[~outliers])

                # See if the cluster is very dispersed
                min_pts = min(50, min(x.shape[0] - 1, max(5, round(0.1 * x.shape[0]))))
                nn = NearestNeighbors(n_neighbors=min_pts, algorithm=&#34;ball_tree&#34;, n_jobs=4)
                nn.fit(xy)
                knn = nn.kneighbors_graph(mode=&#39;distance&#39;)
                k_radius = knn.max(axis=1).toarray()
                epsilon = np.percentile(k_radius, 70)
                # Not too many outliers, and not too dispersed
                if outliers.sum() &lt;= 3 and (np.sqrt(x**2 + y**2) &lt; epsilon).sum() &gt;= min_pts * 0.5:
                        return np.zeros(embedding.shape[0], dtype=&#39;int&#39;)

                # Too many outliers, or too dispersed
                clusterer = DBSCAN(eps=epsilon, min_samples=round(min_pts * 0.5))
                return clusterer.fit_predict(xy)

        @requires(&#34;Embedding&#34;, &#34;float32&#34;, (&#34;cells&#34;, 2))
        @requires(&#34;ManifoldIndices&#34;, &#34;uint32&#34;, (None, 2))
        @requires(&#34;ManifoldWeights&#34;, &#34;float32&#34;, (None))
        @creates(&#34;Clusters&#34;, &#34;uint32&#34;, (&#34;cells&#34;,))
        def fit(self, ws: shoji.WorkspaceManager, save: bool = False) -&gt; np.ndarray:
                &#34;&#34;&#34;
                Given a sparse adjacency matrix, perform Louvain clustering, then polish the result

                Args:
                        ws              The shoji Workspace

                Returns:
                        labels: The cluster labels
                &#34;&#34;&#34;
                logging.info(&#34; PolishedLouvain: Louvain community detection&#34;)
                rc = self.ManifoldIndices[...]
                knn = sparse.coo_matrix((self.ManifoldWeights[...], (rc[:, 0].T, rc[:, 1].T)))
                g = nx.from_scipy_sparse_matrix(knn)
                partitions = community.best_partition(g, resolution=self.resolution, randomize=False)
                labels = np.array([partitions[key] for key in range(knn.shape[0])])
                logging.info(f&#34; PolishedLouvain: Found {labels.max() + 1} initial clusters&#34;)

                # Mark outliers using DBSCAN on the embedding
                logging.info(&#34; PolishedLouvain: Using DBSCAN to mark outliers&#34;)
                xy = self.Embedding[...]
                nn = NearestNeighbors(n_neighbors=10, algorithm=&#34;ball_tree&#34;, n_jobs=-1)
                nn.fit(xy)
                knn = nn.kneighbors_graph(mode=&#39;distance&#39;)
                k_radius = knn.max(axis=1).toarray()
                epsilon = np.percentile(k_radius, 80)
                clusterer = DBSCAN(eps=epsilon, min_samples=10)
                outliers = (clusterer.fit_predict(xy) == -1)
                labels[outliers] = -1
                logging.info(f&#34; PolishedLouvain: Found {labels.max() + 1} clusters after marking outliers using DBSCAN&#34;)

                # Mark outliers as cells in bad neighborhoods
                logging.info(&#34; PolishedLouvain: Using neighborhood to mark outliers&#34;)
                knn = nn.kneighbors_graph(mode=&#39;connectivity&#39;).tocoo()
                temp = []
                for ix in range(labels.shape[0]):
                        if labels[ix] == -1:
                                temp.append(-1)
                                continue
                        neighbors = knn.col[np.where(knn.row == ix)[0]]
                        neighborhood = labels[neighbors] == labels[ix]
                        if neighborhood.sum() / neighborhood.shape[0] &gt; 0.2:
                                temp.append(labels[ix])
                        else:
                                temp.append(-1)
                labels = np.array(temp)

                # Renumber the clusters
                retain = sorted(list(set(labels)))
                d = dict(zip(retain, np.arange(-1, len(set(retain)))))
                labels = np.array([d[x] if x in d else -1 for x in labels])
                logging.info(f&#34; PolishedLouvain: Found {labels.max() + 1} clusters after marking outliers using neighborhood&#34;)

                # Break clusters based on the embedding
                logging.info(&#34; PolishedLouvain: Breaking clusters&#34;)
                max_label = 0
                labels2 = np.copy(labels)
                for lbl in range(labels.max() + 1):
                        cluster = labels == lbl
                        if cluster.sum() &lt; 10:
                                continue
                        adjusted = self._break_cluster(xy[cluster, :])
                        new_labels = np.copy(adjusted)
                        for i in range(np.max(adjusted) + 1):
                                new_labels[adjusted == i] = i + max_label
                        max_label = max_label + np.max(adjusted) + 1
                        labels2[cluster] = new_labels
                labels = labels2
                logging.info(f&#34; PolishedLouvain: Found {labels.max() + 1} clusters after breaking clusters on the embedding&#34;)

                # Set the local cluster label to the local majority vote
                logging.info(&#34; PolishedLouvain: Smoothing cluster identity on the embedding&#34;)
                nn = NearestNeighbors(n_neighbors=10, algorithm=&#34;ball_tree&#34;, n_jobs=4)
                nn.fit(xy)
                knn = nn.kneighbors_graph(mode=&#39;connectivity&#39;).tocoo()
                temp = []
                for ix in range(labels.shape[0]):
                        neighbors = knn.col[np.where(knn.row == ix)[0]]
                        temp.append(mode(labels[neighbors])[0][0])
                labels = np.array(temp)
                logging.info(f&#34; PolishedLouvain: Found {labels.max() + 1} clusters after smoothing clusters on the embedding&#34;)

                # Mark tiny clusters as outliers
                logging.info(&#34; PolishedLouvain: Marking tiny clusters as outliers&#34;)
                ix, counts = np.unique(labels, return_counts=True)
                labels[np.isin(labels, ix[counts &lt; self.min_cells])] = -1

                # Renumber the clusters (since some clusters might have been lost in poor neighborhoods)
                retain = list(set(labels))
                if -1 not in retain:
                        retain.append(-1)
                retain = sorted(retain)
                d = dict(zip(retain, np.arange(-1, len(set(retain)))))
                labels = np.array([d[x] if x in d else -1 for x in labels])
                logging.info(f&#34; PolishedLouvain: Found {labels.max() + 1} clusters after marking tiny clusters as outliers&#34;)

                if np.all(labels &lt; 0):
                        logging.warn(&#34; PolishedLouvain: All cells were determined to be outliers!&#34;)
                        return np.zeros_like(labels)

                if np.any(labels == -1):
                        # Assign each outlier to the same cluster as the nearest non-outlier
                        nn = NearestNeighbors(n_neighbors=50, algorithm=&#34;ball_tree&#34;)
                        nn.fit(xy[labels &gt;= 0])
                        nearest = nn.kneighbors(xy[labels == -1], n_neighbors=1, return_distance=False)
                        labels[labels == -1] = labels[labels &gt;= 0][nearest.flat[:]]
                logging.info(f&#34; PolishedLouvain: Found {labels.max() + 1} clusters&#34;)
                return labels</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="cytograph.module.Module" href="../module.html#cytograph.module.Module">Module</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="cytograph.clustering.polished_louvain.PolishedLouvain.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, ws: shoji.workspace.WorkspaceManager, save: bool = False) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Given a sparse adjacency matrix, perform Louvain clustering, then polish the result</p>
<h2 id="args">Args</h2>
<p>ws
The shoji Workspace</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>labels</code></dt>
<dd>The cluster labels</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@requires(&#34;Embedding&#34;, &#34;float32&#34;, (&#34;cells&#34;, 2))
@requires(&#34;ManifoldIndices&#34;, &#34;uint32&#34;, (None, 2))
@requires(&#34;ManifoldWeights&#34;, &#34;float32&#34;, (None))
@creates(&#34;Clusters&#34;, &#34;uint32&#34;, (&#34;cells&#34;,))
def fit(self, ws: shoji.WorkspaceManager, save: bool = False) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Given a sparse adjacency matrix, perform Louvain clustering, then polish the result

        Args:
                ws              The shoji Workspace

        Returns:
                labels: The cluster labels
        &#34;&#34;&#34;
        logging.info(&#34; PolishedLouvain: Louvain community detection&#34;)
        rc = self.ManifoldIndices[...]
        knn = sparse.coo_matrix((self.ManifoldWeights[...], (rc[:, 0].T, rc[:, 1].T)))
        g = nx.from_scipy_sparse_matrix(knn)
        partitions = community.best_partition(g, resolution=self.resolution, randomize=False)
        labels = np.array([partitions[key] for key in range(knn.shape[0])])
        logging.info(f&#34; PolishedLouvain: Found {labels.max() + 1} initial clusters&#34;)

        # Mark outliers using DBSCAN on the embedding
        logging.info(&#34; PolishedLouvain: Using DBSCAN to mark outliers&#34;)
        xy = self.Embedding[...]
        nn = NearestNeighbors(n_neighbors=10, algorithm=&#34;ball_tree&#34;, n_jobs=-1)
        nn.fit(xy)
        knn = nn.kneighbors_graph(mode=&#39;distance&#39;)
        k_radius = knn.max(axis=1).toarray()
        epsilon = np.percentile(k_radius, 80)
        clusterer = DBSCAN(eps=epsilon, min_samples=10)
        outliers = (clusterer.fit_predict(xy) == -1)
        labels[outliers] = -1
        logging.info(f&#34; PolishedLouvain: Found {labels.max() + 1} clusters after marking outliers using DBSCAN&#34;)

        # Mark outliers as cells in bad neighborhoods
        logging.info(&#34; PolishedLouvain: Using neighborhood to mark outliers&#34;)
        knn = nn.kneighbors_graph(mode=&#39;connectivity&#39;).tocoo()
        temp = []
        for ix in range(labels.shape[0]):
                if labels[ix] == -1:
                        temp.append(-1)
                        continue
                neighbors = knn.col[np.where(knn.row == ix)[0]]
                neighborhood = labels[neighbors] == labels[ix]
                if neighborhood.sum() / neighborhood.shape[0] &gt; 0.2:
                        temp.append(labels[ix])
                else:
                        temp.append(-1)
        labels = np.array(temp)

        # Renumber the clusters
        retain = sorted(list(set(labels)))
        d = dict(zip(retain, np.arange(-1, len(set(retain)))))
        labels = np.array([d[x] if x in d else -1 for x in labels])
        logging.info(f&#34; PolishedLouvain: Found {labels.max() + 1} clusters after marking outliers using neighborhood&#34;)

        # Break clusters based on the embedding
        logging.info(&#34; PolishedLouvain: Breaking clusters&#34;)
        max_label = 0
        labels2 = np.copy(labels)
        for lbl in range(labels.max() + 1):
                cluster = labels == lbl
                if cluster.sum() &lt; 10:
                        continue
                adjusted = self._break_cluster(xy[cluster, :])
                new_labels = np.copy(adjusted)
                for i in range(np.max(adjusted) + 1):
                        new_labels[adjusted == i] = i + max_label
                max_label = max_label + np.max(adjusted) + 1
                labels2[cluster] = new_labels
        labels = labels2
        logging.info(f&#34; PolishedLouvain: Found {labels.max() + 1} clusters after breaking clusters on the embedding&#34;)

        # Set the local cluster label to the local majority vote
        logging.info(&#34; PolishedLouvain: Smoothing cluster identity on the embedding&#34;)
        nn = NearestNeighbors(n_neighbors=10, algorithm=&#34;ball_tree&#34;, n_jobs=4)
        nn.fit(xy)
        knn = nn.kneighbors_graph(mode=&#39;connectivity&#39;).tocoo()
        temp = []
        for ix in range(labels.shape[0]):
                neighbors = knn.col[np.where(knn.row == ix)[0]]
                temp.append(mode(labels[neighbors])[0][0])
        labels = np.array(temp)
        logging.info(f&#34; PolishedLouvain: Found {labels.max() + 1} clusters after smoothing clusters on the embedding&#34;)

        # Mark tiny clusters as outliers
        logging.info(&#34; PolishedLouvain: Marking tiny clusters as outliers&#34;)
        ix, counts = np.unique(labels, return_counts=True)
        labels[np.isin(labels, ix[counts &lt; self.min_cells])] = -1

        # Renumber the clusters (since some clusters might have been lost in poor neighborhoods)
        retain = list(set(labels))
        if -1 not in retain:
                retain.append(-1)
        retain = sorted(retain)
        d = dict(zip(retain, np.arange(-1, len(set(retain)))))
        labels = np.array([d[x] if x in d else -1 for x in labels])
        logging.info(f&#34; PolishedLouvain: Found {labels.max() + 1} clusters after marking tiny clusters as outliers&#34;)

        if np.all(labels &lt; 0):
                logging.warn(&#34; PolishedLouvain: All cells were determined to be outliers!&#34;)
                return np.zeros_like(labels)

        if np.any(labels == -1):
                # Assign each outlier to the same cluster as the nearest non-outlier
                nn = NearestNeighbors(n_neighbors=50, algorithm=&#34;ball_tree&#34;)
                nn.fit(xy[labels &gt;= 0])
                nearest = nn.kneighbors(xy[labels == -1], n_neighbors=1, return_distance=False)
                labels[labels == -1] = labels[labels &gt;= 0][nearest.flat[:]]
        logging.info(f&#34; PolishedLouvain: Found {labels.max() + 1} clusters&#34;)
        return labels</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="cytograph.clustering" href="index.html">cytograph.clustering</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="cytograph.clustering.polished_louvain.is_outlier" href="#cytograph.clustering.polished_louvain.is_outlier">is_outlier</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="cytograph.clustering.polished_louvain.PolishedLouvain" href="#cytograph.clustering.polished_louvain.PolishedLouvain">PolishedLouvain</a></code></h4>
<ul class="">
<li><code><a title="cytograph.clustering.polished_louvain.PolishedLouvain.fit" href="#cytograph.clustering.polished_louvain.PolishedLouvain.fit">fit</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.4</a>.</p>
</footer>
</body>
</html>