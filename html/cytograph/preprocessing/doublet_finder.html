<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.4" />
<title>cytograph.preprocessing.doublet_finder API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>cytograph.preprocessing.doublet_finder</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># This function written by Kimberly Siletti and is based on doubletFinder.R as forwarded by the Allen Institute:
#
# &#34;Doublet detection in single-cell RNA sequencing data
#
# This function generates artificial nearest neighbors from existing single-cell RNA
# sequencing data. First, real and artificial data are merged. Second, dimension reduction
# is performed on the merged real-artificial dataset using PCA. Third, the proportion of
# artificial nearest neighbors is defined for each real cell. Finally, real cells are rank-
# ordered and predicted doublets are defined via thresholding based on the expected number
# of doublets.
#
# @param seu A fully-processed Seurat object (i.e. after normalization, variable gene definition,
# scaling, PCA, and tSNE).
# @param expected.doublets The number of doublets expected to be present in the original data.
# This value can best be estimated from cell loading densities into the 10X/Drop-Seq device.
# @param porportion.artificial The proportion (from 0-1) of the merged real-artificial dataset
# that is artificial. In other words, this argument defines the total number of artificial doublets.
# Default is set to 25%, based on optimization on PBMCs (see McGinnis, Murrow and Gartner 2018, BioRxiv).
# @param proportion.NN The proportion (from 0-1) of the merged real-artificial dataset used to define
# each cell&#39;s neighborhood in PC space. Default set to 1%, based on optimization on PBMCs (see McGinnis,
# Murrow and Gartner 2018, BioRxiv).
# @return An updated Seurat object with metadata for pANN values and doublet predictions.
# @export
# @examples
# seu &lt;- doubletFinder(seu, expected.doublets = 1000, proportion.artificial = 0.25, proportion.NN = 0.01)&#34;


import logging
from typing import Tuple
import numpy as np
from sklearn.decomposition import PCA
from sklearn.neighbors import NearestNeighbors
import shoji
from cytograph.enrichment import FeatureSelectionByVariance
from cytograph import requires, creates, Module
from sklearn.neighbors import KernelDensity
from sklearn.cluster import KMeans
from unidip import UniDip


class DoubletFinder(Module):
        def __init__(self, proportion_artificial: float = 0.2, fixed_threshold: float = None, max_threshold: float = 1, k: int = None, **kwargs) -&gt; None:
                &#34;&#34;&#34;
                Find doublets using the doublet-finder algorithm.

                Args:
                        proportion_artifical:           How many artifical doublets to create
                        fixed_threshold:                        Optional fixed threshold to use
                        max_threshold:                          Max threshold to use
                        k:                                                      Number of neighbors

                Creates:
                        DoubletScore            A doublet score in the interval [0, 1]
                        DoubletFlag                     0: singlet, 1: doublet, 2: neighbor of a doublet
                &#34;&#34;&#34;
                super().__init__(**kwargs)
                self.proportion_artificial = proportion_artificial
                self.fixed_threshold = fixed_threshold
                self.max_threshold = max_threshold
                self.k = k

        @requires(&#34;Expression&#34;, None, (&#34;cells&#34;, &#34;genes&#34;))
        @creates(&#34;DoubletScore&#34;, &#34;float32&#34;, (&#34;cells&#34;,))
        @creates(&#34;DoubletFlag&#34;, &#34;bool&#34;, (&#34;cells&#34;,))
        def fit(self, ws: shoji.WorkspaceManager, save: bool = False) -&gt; Tuple[np.ndarray, np.ndarray]:
                # WARNING: for historical reasons, all the processing here is done with matrices oriented (genes, cells)
                # Step 1: Generate artificial doublets from input
                logging.info(&#34; DoubletFinder: Creating artificial doublets&#34;)
                n_real_cells = ws.cells.length
                n_genes = ws.genes.length
                n_doublets = int(n_real_cells / (1 - self.proportion_artificial) - n_real_cells)
                doublets = np.zeros((n_genes, n_doublets))
                expression = self.Expression[:]
                for i in range(n_doublets):
                        (a, b) = np.random.choice(n_real_cells, size=2, replace=False)
                        doublets[:, i] = expression[a] + expression[b]

                data_wdoublets = np.concatenate((expression.T, doublets), axis=1)  # Transpose the expression matrix to be (genes, cells)
                logging.info(&#34; DoubletFinder: Feature selection and dimensionality reduction&#34;)
                genes = FeatureSelectionByVariance(500).fit(ws)
                logging.info(&#34; DoubletFinder: Computing size factors&#34;)
                f = np.divide(data_wdoublets.sum(axis=0), 10e4)
                logging.info(&#34; DoubletFinder: Normalizing by size factors&#34;)
                norm_data = np.divide(data_wdoublets, f)
                logging.info(&#34; DoubletFinder: Log transforming&#34;)
                norm_data = np.log(norm_data + 1)
                logging.info(&#34; DoubletFinder: Extracting subset of selected genes&#34;)
                subset = norm_data[genes, :].T
                logging.info(f&#34; DoubletFinder: PCA to 50 components with data of shape {subset.shape}&#34;)
                pca = PCA(n_components=50).fit_transform(subset)
                logging.info(&#34; DoubletFinder: PCA to 50 components done&#34;)
                
                if self.k is None:
                        k = int(np.min([100, n_real_cells * 0.01]))
                else:
                        k = self.k

                logging.info(f&#34; DoubletFinder: Initializing NN structure with k = {k}&#34;)
                knn_result = NearestNeighbors(n_neighbors=k, metric=&#39;euclidean&#39;, n_jobs=4)
                knn_result.fit(pca)
                knn_dist, knn_idx = knn_result.kneighbors(X=pca, return_distance=True)

                knn_result1 = NearestNeighbors(n_neighbors=k, metric=&#39;euclidean&#39;, n_jobs=4)
                knn_result1.fit(pca[0:n_real_cells, :])
                knn_dist1, _ = knn_result1.kneighbors(X=pca[n_real_cells + 1:, :], n_neighbors=10)
                knn_dist_rc, knn_idx_rc = knn_result1.kneighbors(X=pca[0:n_real_cells, :], return_distance=True)

                logging.info(f&#34; DoubletFinder: Finding the doublet score threshold&#34;)
                dist_th = np.mean(knn_dist1.flatten()) + 1.64 * np.std(knn_dist1.flatten())

                doublet_freq = np.logical_and(knn_idx &gt; n_real_cells, knn_dist &lt; dist_th)
                doublet_freq_A = doublet_freq[n_real_cells:n_real_cells + n_doublets, :]
                mean1 = doublet_freq_A.mean(axis=1)
                mean2 = doublet_freq_A[:, 0:int(np.ceil(k / 2))].mean(axis=1)
                doublet_score_A = np.maximum(mean1, mean2)
                
                doublet_freq = doublet_freq[0:n_real_cells, :]
                mean1 = doublet_freq.mean(axis=1)
                mean2 = doublet_freq[:, 0:int(np.ceil(k / 2))].mean(axis=1)
                doublet_score = np.maximum(mean1, mean2)
                doublet_flag = np.zeros(n_real_cells, int)
                doublet_th1 = 1.0
                doublet_th2 = 1.0
                doublet_th = 1.0
                
                # instantiate and fit the KDE model
                kde = KernelDensity(bandwidth=0.1, kernel=&#39;gaussian&#39;)
                kde.fit(doublet_score_A[:, None])

                # score_samples returns the log of the probability density
                xx = np.linspace(doublet_score_A.min(), doublet_score_A.max(), len(doublet_score_A)).reshape(-1, 1)

                logprob = kde.score_samples(xx)
                if self.fixed_threshold is not None:
                        doublet_th = float(self.fixed_threshold)
                else:
                        # Check if the distribution is bimodal
                        intervals = UniDip(np.exp(logprob)).run()
                        if (len(intervals) &gt; 1):
                                kmeans = KMeans(n_clusters=2).fit(doublet_score_A.reshape(len(doublet_score_A), 1))
                                high_cluster = np.where(kmeans.cluster_centers_ == max(kmeans.cluster_centers_))[0][0]
                                doublet_th1 = np.around(np.min(doublet_score_A[kmeans.labels_ == high_cluster]), decimals=3)
                        
                        # 0.5% for every 1000 cells - the rate of detectable doublets by 10X
                        doublet_th2 = np.percentile(doublet_score, 100 - (5e-4 * n_real_cells))
                        doublet_th2 = np.around(doublet_th2, decimals=3)
                        # The threshold shouldn&#39;t be higher than indicated
                        if doublet_th2 &gt; self.max_threshold:
                                doublet_th2 = self.max_threshold
                        if doublet_th1 &gt; self.max_threshold:
                                doublet_th1 = self.max_threshold
                        if (len(np.where(doublet_score &gt;= doublet_th1)[0]) &gt; (len(np.where(doublet_score &gt;= doublet_th2)[0]))):
                                doublet_th = doublet_th2
                        else:
                                doublet_th = doublet_th1
                logging.info(f&#34; DoubletFinder: Optimal threshold was {doublet_th:.2f}&#34;)
                doublet_flag[doublet_score &gt;= doublet_th] = 1

                logging.info(f&#34; DoubletFinder: Finding doublet neighbors&#34;)
                # Calculate the score for the cells that are nn of the marked doublets
                if (doublet_flag == 1).sum() &gt; 0:
                        pca_rc = pca[0:n_real_cells, :]
                        knn_dist1_rc, _ = knn_result1.kneighbors(X=pca_rc[doublet_flag == 1, :], n_neighbors=10, return_distance=True)

                        dist_th = np.mean(knn_dist1_rc.flatten()) + 1.64 * np.std(knn_dist1_rc.flatten())
                        doublet2_freq = np.logical_and(doublet_flag[knn_idx_rc] == 1, knn_dist_rc &lt; dist_th)
                        doublet2_nn = knn_dist_rc &lt; dist_th
                        doublet2_score = doublet2_freq.sum(axis=1) / doublet2_nn.sum(axis=1)
                        
                        doublet_flag[np.logical_and(doublet_flag == 0, doublet2_score &gt;= doublet_th / 2)] = 2
                        
                logging.info(f&#34; DoubletFinder: Doublet fraction was {100*len(np.where(doublet_flag &gt; 0)[0]) / n_real_cells:.2f}%, i.e. {len(np.where(doublet_flag &gt; 0)[0])} cells&#34;)
                
                return doublet_score, doublet_flag</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="cytograph.preprocessing.doublet_finder.DoubletFinder"><code class="flex name class">
<span>class <span class="ident">DoubletFinder</span></span>
<span>(</span><span>proportion_artificial: float = 0.2, fixed_threshold: float = None, max_threshold: float = 1, k: int = None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Find doublets using the doublet-finder algorithm.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>proportion_artifical</code></strong></dt>
<dd>
<pre><code>  How many artifical doublets to create
</code></pre>
</dd>
<dt><strong><code>fixed_threshold</code></strong></dt>
<dd>
<pre><code>               Optional fixed threshold to use
</code></pre>
</dd>
<dt><strong><code>max_threshold</code></strong></dt>
<dd>
<pre><code>                 Max threshold to use
</code></pre>
</dd>
<dt><strong><code>k</code></strong></dt>
<dd>
<pre><code>                                             Number of neighbors
</code></pre>
</dd>
</dl>
<h2 id="creates">Creates</h2>
<p>DoubletScore
A doublet score in the interval [0, 1]
DoubletFlag
0: singlet, 1: doublet, 2: neighbor of a doublet</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DoubletFinder(Module):
        def __init__(self, proportion_artificial: float = 0.2, fixed_threshold: float = None, max_threshold: float = 1, k: int = None, **kwargs) -&gt; None:
                &#34;&#34;&#34;
                Find doublets using the doublet-finder algorithm.

                Args:
                        proportion_artifical:           How many artifical doublets to create
                        fixed_threshold:                        Optional fixed threshold to use
                        max_threshold:                          Max threshold to use
                        k:                                                      Number of neighbors

                Creates:
                        DoubletScore            A doublet score in the interval [0, 1]
                        DoubletFlag                     0: singlet, 1: doublet, 2: neighbor of a doublet
                &#34;&#34;&#34;
                super().__init__(**kwargs)
                self.proportion_artificial = proportion_artificial
                self.fixed_threshold = fixed_threshold
                self.max_threshold = max_threshold
                self.k = k

        @requires(&#34;Expression&#34;, None, (&#34;cells&#34;, &#34;genes&#34;))
        @creates(&#34;DoubletScore&#34;, &#34;float32&#34;, (&#34;cells&#34;,))
        @creates(&#34;DoubletFlag&#34;, &#34;bool&#34;, (&#34;cells&#34;,))
        def fit(self, ws: shoji.WorkspaceManager, save: bool = False) -&gt; Tuple[np.ndarray, np.ndarray]:
                # WARNING: for historical reasons, all the processing here is done with matrices oriented (genes, cells)
                # Step 1: Generate artificial doublets from input
                logging.info(&#34; DoubletFinder: Creating artificial doublets&#34;)
                n_real_cells = ws.cells.length
                n_genes = ws.genes.length
                n_doublets = int(n_real_cells / (1 - self.proportion_artificial) - n_real_cells)
                doublets = np.zeros((n_genes, n_doublets))
                expression = self.Expression[:]
                for i in range(n_doublets):
                        (a, b) = np.random.choice(n_real_cells, size=2, replace=False)
                        doublets[:, i] = expression[a] + expression[b]

                data_wdoublets = np.concatenate((expression.T, doublets), axis=1)  # Transpose the expression matrix to be (genes, cells)
                logging.info(&#34; DoubletFinder: Feature selection and dimensionality reduction&#34;)
                genes = FeatureSelectionByVariance(500).fit(ws)
                logging.info(&#34; DoubletFinder: Computing size factors&#34;)
                f = np.divide(data_wdoublets.sum(axis=0), 10e4)
                logging.info(&#34; DoubletFinder: Normalizing by size factors&#34;)
                norm_data = np.divide(data_wdoublets, f)
                logging.info(&#34; DoubletFinder: Log transforming&#34;)
                norm_data = np.log(norm_data + 1)
                logging.info(&#34; DoubletFinder: Extracting subset of selected genes&#34;)
                subset = norm_data[genes, :].T
                logging.info(f&#34; DoubletFinder: PCA to 50 components with data of shape {subset.shape}&#34;)
                pca = PCA(n_components=50).fit_transform(subset)
                logging.info(&#34; DoubletFinder: PCA to 50 components done&#34;)
                
                if self.k is None:
                        k = int(np.min([100, n_real_cells * 0.01]))
                else:
                        k = self.k

                logging.info(f&#34; DoubletFinder: Initializing NN structure with k = {k}&#34;)
                knn_result = NearestNeighbors(n_neighbors=k, metric=&#39;euclidean&#39;, n_jobs=4)
                knn_result.fit(pca)
                knn_dist, knn_idx = knn_result.kneighbors(X=pca, return_distance=True)

                knn_result1 = NearestNeighbors(n_neighbors=k, metric=&#39;euclidean&#39;, n_jobs=4)
                knn_result1.fit(pca[0:n_real_cells, :])
                knn_dist1, _ = knn_result1.kneighbors(X=pca[n_real_cells + 1:, :], n_neighbors=10)
                knn_dist_rc, knn_idx_rc = knn_result1.kneighbors(X=pca[0:n_real_cells, :], return_distance=True)

                logging.info(f&#34; DoubletFinder: Finding the doublet score threshold&#34;)
                dist_th = np.mean(knn_dist1.flatten()) + 1.64 * np.std(knn_dist1.flatten())

                doublet_freq = np.logical_and(knn_idx &gt; n_real_cells, knn_dist &lt; dist_th)
                doublet_freq_A = doublet_freq[n_real_cells:n_real_cells + n_doublets, :]
                mean1 = doublet_freq_A.mean(axis=1)
                mean2 = doublet_freq_A[:, 0:int(np.ceil(k / 2))].mean(axis=1)
                doublet_score_A = np.maximum(mean1, mean2)
                
                doublet_freq = doublet_freq[0:n_real_cells, :]
                mean1 = doublet_freq.mean(axis=1)
                mean2 = doublet_freq[:, 0:int(np.ceil(k / 2))].mean(axis=1)
                doublet_score = np.maximum(mean1, mean2)
                doublet_flag = np.zeros(n_real_cells, int)
                doublet_th1 = 1.0
                doublet_th2 = 1.0
                doublet_th = 1.0
                
                # instantiate and fit the KDE model
                kde = KernelDensity(bandwidth=0.1, kernel=&#39;gaussian&#39;)
                kde.fit(doublet_score_A[:, None])

                # score_samples returns the log of the probability density
                xx = np.linspace(doublet_score_A.min(), doublet_score_A.max(), len(doublet_score_A)).reshape(-1, 1)

                logprob = kde.score_samples(xx)
                if self.fixed_threshold is not None:
                        doublet_th = float(self.fixed_threshold)
                else:
                        # Check if the distribution is bimodal
                        intervals = UniDip(np.exp(logprob)).run()
                        if (len(intervals) &gt; 1):
                                kmeans = KMeans(n_clusters=2).fit(doublet_score_A.reshape(len(doublet_score_A), 1))
                                high_cluster = np.where(kmeans.cluster_centers_ == max(kmeans.cluster_centers_))[0][0]
                                doublet_th1 = np.around(np.min(doublet_score_A[kmeans.labels_ == high_cluster]), decimals=3)
                        
                        # 0.5% for every 1000 cells - the rate of detectable doublets by 10X
                        doublet_th2 = np.percentile(doublet_score, 100 - (5e-4 * n_real_cells))
                        doublet_th2 = np.around(doublet_th2, decimals=3)
                        # The threshold shouldn&#39;t be higher than indicated
                        if doublet_th2 &gt; self.max_threshold:
                                doublet_th2 = self.max_threshold
                        if doublet_th1 &gt; self.max_threshold:
                                doublet_th1 = self.max_threshold
                        if (len(np.where(doublet_score &gt;= doublet_th1)[0]) &gt; (len(np.where(doublet_score &gt;= doublet_th2)[0]))):
                                doublet_th = doublet_th2
                        else:
                                doublet_th = doublet_th1
                logging.info(f&#34; DoubletFinder: Optimal threshold was {doublet_th:.2f}&#34;)
                doublet_flag[doublet_score &gt;= doublet_th] = 1

                logging.info(f&#34; DoubletFinder: Finding doublet neighbors&#34;)
                # Calculate the score for the cells that are nn of the marked doublets
                if (doublet_flag == 1).sum() &gt; 0:
                        pca_rc = pca[0:n_real_cells, :]
                        knn_dist1_rc, _ = knn_result1.kneighbors(X=pca_rc[doublet_flag == 1, :], n_neighbors=10, return_distance=True)

                        dist_th = np.mean(knn_dist1_rc.flatten()) + 1.64 * np.std(knn_dist1_rc.flatten())
                        doublet2_freq = np.logical_and(doublet_flag[knn_idx_rc] == 1, knn_dist_rc &lt; dist_th)
                        doublet2_nn = knn_dist_rc &lt; dist_th
                        doublet2_score = doublet2_freq.sum(axis=1) / doublet2_nn.sum(axis=1)
                        
                        doublet_flag[np.logical_and(doublet_flag == 0, doublet2_score &gt;= doublet_th / 2)] = 2
                        
                logging.info(f&#34; DoubletFinder: Doublet fraction was {100*len(np.where(doublet_flag &gt; 0)[0]) / n_real_cells:.2f}%, i.e. {len(np.where(doublet_flag &gt; 0)[0])} cells&#34;)
                
                return doublet_score, doublet_flag</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="cytograph.module.Module" href="../module.html#cytograph.module.Module">Module</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="cytograph.preprocessing.doublet_finder.DoubletFinder.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, ws: shoji.workspace.WorkspaceManager, save: bool = False) ‑> Tuple[numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@requires(&#34;Expression&#34;, None, (&#34;cells&#34;, &#34;genes&#34;))
@creates(&#34;DoubletScore&#34;, &#34;float32&#34;, (&#34;cells&#34;,))
@creates(&#34;DoubletFlag&#34;, &#34;bool&#34;, (&#34;cells&#34;,))
def fit(self, ws: shoji.WorkspaceManager, save: bool = False) -&gt; Tuple[np.ndarray, np.ndarray]:
        # WARNING: for historical reasons, all the processing here is done with matrices oriented (genes, cells)
        # Step 1: Generate artificial doublets from input
        logging.info(&#34; DoubletFinder: Creating artificial doublets&#34;)
        n_real_cells = ws.cells.length
        n_genes = ws.genes.length
        n_doublets = int(n_real_cells / (1 - self.proportion_artificial) - n_real_cells)
        doublets = np.zeros((n_genes, n_doublets))
        expression = self.Expression[:]
        for i in range(n_doublets):
                (a, b) = np.random.choice(n_real_cells, size=2, replace=False)
                doublets[:, i] = expression[a] + expression[b]

        data_wdoublets = np.concatenate((expression.T, doublets), axis=1)  # Transpose the expression matrix to be (genes, cells)
        logging.info(&#34; DoubletFinder: Feature selection and dimensionality reduction&#34;)
        genes = FeatureSelectionByVariance(500).fit(ws)
        logging.info(&#34; DoubletFinder: Computing size factors&#34;)
        f = np.divide(data_wdoublets.sum(axis=0), 10e4)
        logging.info(&#34; DoubletFinder: Normalizing by size factors&#34;)
        norm_data = np.divide(data_wdoublets, f)
        logging.info(&#34; DoubletFinder: Log transforming&#34;)
        norm_data = np.log(norm_data + 1)
        logging.info(&#34; DoubletFinder: Extracting subset of selected genes&#34;)
        subset = norm_data[genes, :].T
        logging.info(f&#34; DoubletFinder: PCA to 50 components with data of shape {subset.shape}&#34;)
        pca = PCA(n_components=50).fit_transform(subset)
        logging.info(&#34; DoubletFinder: PCA to 50 components done&#34;)
        
        if self.k is None:
                k = int(np.min([100, n_real_cells * 0.01]))
        else:
                k = self.k

        logging.info(f&#34; DoubletFinder: Initializing NN structure with k = {k}&#34;)
        knn_result = NearestNeighbors(n_neighbors=k, metric=&#39;euclidean&#39;, n_jobs=4)
        knn_result.fit(pca)
        knn_dist, knn_idx = knn_result.kneighbors(X=pca, return_distance=True)

        knn_result1 = NearestNeighbors(n_neighbors=k, metric=&#39;euclidean&#39;, n_jobs=4)
        knn_result1.fit(pca[0:n_real_cells, :])
        knn_dist1, _ = knn_result1.kneighbors(X=pca[n_real_cells + 1:, :], n_neighbors=10)
        knn_dist_rc, knn_idx_rc = knn_result1.kneighbors(X=pca[0:n_real_cells, :], return_distance=True)

        logging.info(f&#34; DoubletFinder: Finding the doublet score threshold&#34;)
        dist_th = np.mean(knn_dist1.flatten()) + 1.64 * np.std(knn_dist1.flatten())

        doublet_freq = np.logical_and(knn_idx &gt; n_real_cells, knn_dist &lt; dist_th)
        doublet_freq_A = doublet_freq[n_real_cells:n_real_cells + n_doublets, :]
        mean1 = doublet_freq_A.mean(axis=1)
        mean2 = doublet_freq_A[:, 0:int(np.ceil(k / 2))].mean(axis=1)
        doublet_score_A = np.maximum(mean1, mean2)
        
        doublet_freq = doublet_freq[0:n_real_cells, :]
        mean1 = doublet_freq.mean(axis=1)
        mean2 = doublet_freq[:, 0:int(np.ceil(k / 2))].mean(axis=1)
        doublet_score = np.maximum(mean1, mean2)
        doublet_flag = np.zeros(n_real_cells, int)
        doublet_th1 = 1.0
        doublet_th2 = 1.0
        doublet_th = 1.0
        
        # instantiate and fit the KDE model
        kde = KernelDensity(bandwidth=0.1, kernel=&#39;gaussian&#39;)
        kde.fit(doublet_score_A[:, None])

        # score_samples returns the log of the probability density
        xx = np.linspace(doublet_score_A.min(), doublet_score_A.max(), len(doublet_score_A)).reshape(-1, 1)

        logprob = kde.score_samples(xx)
        if self.fixed_threshold is not None:
                doublet_th = float(self.fixed_threshold)
        else:
                # Check if the distribution is bimodal
                intervals = UniDip(np.exp(logprob)).run()
                if (len(intervals) &gt; 1):
                        kmeans = KMeans(n_clusters=2).fit(doublet_score_A.reshape(len(doublet_score_A), 1))
                        high_cluster = np.where(kmeans.cluster_centers_ == max(kmeans.cluster_centers_))[0][0]
                        doublet_th1 = np.around(np.min(doublet_score_A[kmeans.labels_ == high_cluster]), decimals=3)
                
                # 0.5% for every 1000 cells - the rate of detectable doublets by 10X
                doublet_th2 = np.percentile(doublet_score, 100 - (5e-4 * n_real_cells))
                doublet_th2 = np.around(doublet_th2, decimals=3)
                # The threshold shouldn&#39;t be higher than indicated
                if doublet_th2 &gt; self.max_threshold:
                        doublet_th2 = self.max_threshold
                if doublet_th1 &gt; self.max_threshold:
                        doublet_th1 = self.max_threshold
                if (len(np.where(doublet_score &gt;= doublet_th1)[0]) &gt; (len(np.where(doublet_score &gt;= doublet_th2)[0]))):
                        doublet_th = doublet_th2
                else:
                        doublet_th = doublet_th1
        logging.info(f&#34; DoubletFinder: Optimal threshold was {doublet_th:.2f}&#34;)
        doublet_flag[doublet_score &gt;= doublet_th] = 1

        logging.info(f&#34; DoubletFinder: Finding doublet neighbors&#34;)
        # Calculate the score for the cells that are nn of the marked doublets
        if (doublet_flag == 1).sum() &gt; 0:
                pca_rc = pca[0:n_real_cells, :]
                knn_dist1_rc, _ = knn_result1.kneighbors(X=pca_rc[doublet_flag == 1, :], n_neighbors=10, return_distance=True)

                dist_th = np.mean(knn_dist1_rc.flatten()) + 1.64 * np.std(knn_dist1_rc.flatten())
                doublet2_freq = np.logical_and(doublet_flag[knn_idx_rc] == 1, knn_dist_rc &lt; dist_th)
                doublet2_nn = knn_dist_rc &lt; dist_th
                doublet2_score = doublet2_freq.sum(axis=1) / doublet2_nn.sum(axis=1)
                
                doublet_flag[np.logical_and(doublet_flag == 0, doublet2_score &gt;= doublet_th / 2)] = 2
                
        logging.info(f&#34; DoubletFinder: Doublet fraction was {100*len(np.where(doublet_flag &gt; 0)[0]) / n_real_cells:.2f}%, i.e. {len(np.where(doublet_flag &gt; 0)[0])} cells&#34;)
        
        return doublet_score, doublet_flag</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="cytograph.preprocessing" href="index.html">cytograph.preprocessing</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="cytograph.preprocessing.doublet_finder.DoubletFinder" href="#cytograph.preprocessing.doublet_finder.DoubletFinder">DoubletFinder</a></code></h4>
<ul class="">
<li><code><a title="cytograph.preprocessing.doublet_finder.DoubletFinder.fit" href="#cytograph.preprocessing.doublet_finder.DoubletFinder.fit">fit</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.4</a>.</p>
</footer>
</body>
</html>